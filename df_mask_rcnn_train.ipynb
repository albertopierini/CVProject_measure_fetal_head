{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "df_mask_rcnn_train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/albertopierini/CVProject_measure_fetal_head/blob/master/df_mask_rcnn_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBYcIQmqPcJT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Installazione dipendenze\n",
        " \n",
        "#!git clone https://github.com/matterport/Mask_RCNN.git\n",
        "#!pip install pycocotools\n",
        "#!pip install mrcnn\n",
        " \n",
        "#VERSIONI TENSORFLOW\n",
        "#!pip install tensorflow\n",
        "#!pip install tensorflow==1.4\n",
        "#!pip install tensorflow-gpu==1.9.0\n",
        "#!pip install tf-nightly-gpu\n",
        " \n",
        "'''\n",
        "!pip install tensorflow==1.15.2\n",
        "!pip install tensorflow-gpu==1.15.2\n",
        "!pip install keras==2.2.0\n",
        "'''\n",
        "# CONDA 10 & TF-GPU 1.14 (metodo 2)\n",
        "#!wget https://developer.nvidia.com/compute/cuda/10.0/Prod/local_installers/cuda-repo-ubuntu1604-10-0-local-10.0.130-410.48_1.0-1_amd64 -O cuda-repo-ubuntu1604-10-0-local-10.0.130-410.48_1.0-1_amd64.deb\n",
        "#!dpkg -i cuda-repo-ubuntu1604-10-0-local-10.0.130-410.48_1.0-1_amd64.deb\n",
        "#!apt-key add /var/cuda-repo-10-0-local-10.0.130-410.48/7fa2af80.pub\n",
        "#!apt-get update\n",
        "#!apt-get install cuda\n",
        " \n",
        "!pip uninstall tensorflow\n",
        "!pip install tensorflow-gpu==1.14\n",
        " \n",
        " \n",
        "!pip install keras==2.2.0\n",
        "print(\"Installed packages\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1aE4rhq2e6C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGbRAz5NPlI0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import dipendenze\n",
        "import numpy\n",
        "import scipy\n",
        "import PIL\n",
        "import tensorflow\n",
        "import skimage\n",
        "import h5py\n",
        "import IPython\n",
        "import cv2\n",
        "import keras\n",
        "import scipy\n",
        "import matplotlib\n",
        "import cython\n",
        "import statistics\n",
        "\n",
        "print(\"All dependencies are installed\")\n",
        "\n",
        "#Test ricerca GPU\n",
        "device_name = tensorflow.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "#import os\n",
        "#os.chdir('/content/Mask_RCNN/samples')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIlS3KbK33sd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install pycocotools"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QFfKQtOPlvC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DEVi3Lk5osF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/content/gdrive/My Drive/mrcnn_training')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgKn68gk6AON",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B49-LdT2TBZ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import skimage.io\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from pycocotools.coco import COCO\n",
        "from config import Config\n",
        "# Root directory of the project\n",
        "ROOT_DIR = os.path.abspath(\"../\")\n",
        "DRIVE_DIR = '/content/gdrive/My Drive/CV Project/'\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        " #Import Mask RCNN\n",
        "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
        "import utils\n",
        "import model as modellib\n",
        "import model2 as modellib2\n",
        "import visualize\n",
        "#Import COCO config\n",
        "sys.path.append(os.path.join(ROOT_DIR, \"samples/coco/\"))  # To find local version\n",
        "#import coco\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# Directory to save logs and trained model\n",
        "MODEL_DIR = os.path.join(DRIVE_DIR, \"logs\")\n",
        "\n",
        "# Local path to trained weights file\n",
        "COCO_MODEL_PATH = \"/content/gdrive/My Drive/CV Project/coco.h5\"\n",
        "\n",
        "# Download COCO trained weights from Releases if needed\n",
        "if not os.path.exists(COCO_MODEL_PATH):\n",
        "    utils.download_trained_weights(COCO_MODEL_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h42cQ3rlTYWi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FetalHeadConfiguration(Config):  \n",
        "  NAME = \"fetalHead\"\n",
        "  BACKBONE = \"resnet101\"\n",
        "  GPU_COUNT = 1\n",
        "  IMAGES_PER_GPU = 4\n",
        "  NUM_CLASSES = 1 + 1 #Background + fetal head\n",
        "  STEPS_PER_EPOCH = 369\n",
        "  IMAGE_MIN_DIM = 512\n",
        "  IMAGE_MAX_DIM = 512\n",
        "  IMAGE_MIN_SCALE = 2.0\n",
        "  MAX_GT_INSTANCES = 1\n",
        "  #LEARNING_RATE = 0.001\n",
        "  LOSS_WEIGHTS = {\n",
        "        \"rpn_class_loss\": 1.,\n",
        "        \"rpn_bbox_loss\": 1.,\n",
        "        \"mrcnn_class_loss\": 1.,\n",
        "        \"mrcnn_bbox_loss\": 1.,\n",
        "        \"mrcnn_mask_loss\": 1.\n",
        "    }\n",
        "  DETECTION_MIN_CONFIDENCE = 0\n",
        "\n",
        "config = FetalHeadConfiguration()\n",
        "config.display()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLIiyZmOUWCR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FetalHeadDataset(utils.Dataset):\n",
        "\n",
        "  def load_fetal_heads(self, read_path, df_path):\n",
        "    self.add_class(\"fetal_head\", 1, \"fetal_head\")\n",
        "    #Read and iterate dataframe\n",
        "    df = pd.read_csv(df_path, sep = ',')\n",
        "    i = 0\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "      image_path = read_path + '/images/' + row['filename']\n",
        "      mask_path = read_path + '/gauss_smussato/' + row['annotation']\n",
        "      #image = skimage.io.imread(image_path)\n",
        "      #height, width = image.shape[:2]\n",
        "      self.add_image(\"fetal_head\", image_id = i, filename = row['filename'], path = image_path, mask_path = mask_path)\n",
        "      i += 1\n",
        "\n",
        "\n",
        "  def load_mask(self, image_id):\n",
        "    #carichiamo la mask e la trasformiamo\n",
        "    image_info = self.image_info[image_id]\n",
        "    mask_path = image_info['mask_path']\n",
        "\n",
        "    mask_image = cv2.imread(mask_path,0)\n",
        "    mask_image = mask_image/255\n",
        "\n",
        "\n",
        "    #ret, binary_mask = cv2.threshold(mask_image_gray,127,1,cv2.THRESH_BINARY)\n",
        "    mask_image = np.expand_dims(mask_image, axis=-1)\n",
        "    return mask_image, np.ones([mask_image.shape[-1]], dtype=np.int32)\n",
        "\n",
        "  def image_reference():\n",
        "    \"\"\"Return the path of the image.\"\"\"\n",
        "    info = self.image_info[image_id]\n",
        "    if info[\"source\"] == \"fetal_head\":\n",
        "      return info[\"path\"]\n",
        "    else:\n",
        "      super(self.__class__, self).image_reference(image_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrBA0XSPB8cb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import model2 as modellib2\n",
        "\n",
        "model2 = modellib2.MaskRCNN(mode=\"training\", config=config, model_dir=MODEL_DIR)\n",
        "\n",
        "model2.load_weights('/content/gdrive/My Drive/fetalhead20200620T1301/mask_rcnn_fetalhead_0022.h5', by_name=True)\n",
        "#model2.load_weights(COCO_MODEL_PATH, by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \"mrcnn_bbox\", \"mrcnn_mask\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuKHe_hFGuBI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imgaug import augmenters as iaa\n",
        "\n",
        "def train(model, read_path):\n",
        "    \"\"\"Train the model.\"\"\"\n",
        "    # Training dataset.\n",
        "    dataset_train = FetalHeadDataset()\n",
        "    df_train_path = '/content/gdrive/My Drive/CV Project/csv/traingauss.csv'\n",
        "    dataset_train.load_fetal_heads(read_path, df_train_path)\n",
        "    dataset_train.prepare()\n",
        "\n",
        "    dataset_validation = FetalHeadDataset()\n",
        "    df_validation_path = '/content/gdrive/My Drive/CV Project/csv/valgauss.csv'\n",
        "    dataset_validation.load_fetal_heads(read_path, df_validation_path)\n",
        "    dataset_validation.prepare()\n",
        "    print('Dataset Validation pronto')\n",
        "\n",
        "    # Image augmentation\n",
        "    # http://imgaug.readthedocs.io/en/latest/source/augmenters.html\n",
        "    \n",
        "    augmentation = iaa.Sequential([\n",
        "            iaa.Affine(\n",
        "                scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
        "                translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
        "                rotate=(-10, 10),\n",
        "                shear=(-2, 2))\n",
        "            ], random_order=True)\n",
        "    \n",
        "    \n",
        "    '''\n",
        "    augmentation = iaa.Sequential([\n",
        "            iaa.Fliplr(0.5), # horizontal flips\n",
        "            iaa.Crop(percent=(0, 0.1)), # random crops\n",
        "            # Small gaussian blur with random sigma between 0 and 0.5.\n",
        "            # But we only blur about 50% of all images.\n",
        "            iaa.Sometimes(0.5,\n",
        "                iaa.GaussianBlur(sigma=(0, 0.5))\n",
        "            ),\n",
        "            # Strengthen or weaken the contrast in each image.\n",
        "            iaa.ContrastNormalization((0.75, 1.5)),\n",
        "            # Make some images brighter and some darker.\n",
        "            # In 20% of all cases, we sample the multiplier once per channel,\n",
        "            # which can end up changing the color of the images.\n",
        "            iaa.Multiply((0.8, 1.2), per_channel=0),\n",
        "            # Apply affine transformations to each image.\n",
        "            # Scale/zoom them, translate/move them, rotate them and shear them.\n",
        "            iaa.Affine(\n",
        "                scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
        "                translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
        "                rotate=(-10, 10),\n",
        "                shear=(-2, 2))\n",
        "            ], random_order=True)\n",
        "    '''\n",
        "\n",
        "\n",
        "    print(\"Train network heads\")\n",
        "    #model.train(dataset_train, dataset_validation,\n",
        "                #learning_rate=config.LEARNING_RATE,\n",
        "                #epochs=30,\n",
        "                #augmentation=augmentation,\n",
        "                #layers='heads')\n",
        "    #print(\"Train network layers 4+\")\n",
        "    #model.train(dataset_train, dataset_validation,\n",
        "     #           learning_rate=config.LEARNING_RATE,\n",
        "      #          epochs=20,\n",
        "       #         augmentation=augmentation,\n",
        "        #        layers='4+')\n",
        "\n",
        "    print(\"Train all layers\")\n",
        "    model.train(dataset_train, dataset_validation,\n",
        "                learning_rate=config.LEARNING_RATE,\n",
        "                epochs=30,\n",
        "                augmentation=augmentation,\n",
        "                layers='all')\n",
        "    #model.keras_model.save_weights('/content/drive/My Drive/Progetto CV fetal head/pesi/mask_rcnn_fetal_head.h5')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sz8yyqxk0Y7u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "read_path = '/content/gdrive/My Drive/train_set'\n",
        "\n",
        "train(model2, read_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8rGOOAUwe9Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2.keras_model.save_weights('/content/gdrive/My Drive/CV Project/pesi/mrcnn_pesi.h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}